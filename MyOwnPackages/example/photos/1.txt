~

e System I operates automatically and quickly, with little or no effort

and no sense of voluntary control.
¢ System 2 allocates attention to the effortful mental activities that de-
“ mand it, including complex computations. The operations of System 2
are often associated with the subjective experience of agency, choice,

and concentration. |
| The highly diverse operations of System 2 have one feature in common:
they require attention and are disrupted when attention is drawn away. }
Here are some examples:
Conflict between an automatic reaction and an intention to control it is

~ common in our lives. We are all familiar with the experience of trying not

to stare at the oddly dressed couple at the neighboring table in a restaurant.

We also know what it is like to force our attention on a boring book, when
we constantly find ourselves returning to the point at which the reading lost
its meaning. Where winters are hard, many drivers have memories of their
car skidding out of control on the ice and of the struggle to follow well-
rehearsed instructions that negate what they would naturally do: “Steer into
the skid, and whatever you do, do not touch the brakes!” And every human
being has had the experience of not telling someone to go to hell! One of the
tasks of System 2 is to overcome the impulses of System 1. In other words,
System 2 is in charge of self-control. |
__ | The question that is most often asked about cognitive illusions is whether
_ they can be overcome. The message of these examples is not encouraging.
Because System 1 operates automatically and cannot be turned off at will,
errors of intuitive thought are often difficult to prevent. Biases cannot al-
ways be avoided, because System 2 may have no clue to the error. Even
when cues to likely errors are available, errors can be prevented only by the
‘enhanced monitoring and effortful activity of System 2. As a way to live
your life, however, continuous vigilance is not necessarily good, and it is
certainly impractical. Constantly questioning our own thinking would be
impossibly tedious, and System 2 is much too slow and inefficient to serve
as a substitute for System 1 in making routine decisions. The best we can do
is a compromise: learn to recognize situations in which mistakes are likely
and try harder to avoid significant mistakes when the stakes are high. The
premise of this book is that it is easier to recognize other people's mistakes
than our own. i

—_ 7
| As you become skilled in a task, its demand for energy diminishes. Stud-
ies of the brain have shown that the pattern of activity associated with an
action changes as skill increases, with fewer brain regions involved. Talent
has similar effects. Highly intelligent individuals need less effort to solve the
same problems, as indicated by both pupil size and brain activity. A general
“law of least effort” applies to cognitive as well as physical exertion. The law
asserts that if there are several ways of achieving the same goal, people will
eventually gravitate to the least demanding course of action. In the economy
of action, effort is a cost, and the acquisition of skill is driven by the balance
of benefits and costs. Laziness is built deep into our nature. i

ame < e
pointless anxious thoughts, |The conclusion is ‘straightforward: self-control
requires attention and effort. Another way of saying this is that controlling
thoughts and behaviors is one of the tasks that System 2 performs. |

A series of surprising experiments by the psychologist Roy Baumeister
f J
PY

_ ‘The evidence is persuasive: activities that impose high demands on System 2
_ tequire self-control, and the exertion of self-control is depleting and un-
pleasant. Unlike cognitive load, ego depletion is at least in part a loss of
motivation. After exerting self-control in one task, you do not feel like mak-
ing an effort in another, although you could do it if you really had to} In
stored in her muscles during a sprint.\ \The bold implication of this idea is
that the effects of ego depletion could be undone by ingesting glucose, and
Baumeister ana his colleagues have confirmed this hypothesis in several

experiments. |

ae ee
| One of the main functions of System 2 is to monitor and control thoughts
and actions “suggested” by System 1, allowing some to be expressed directly
in behavior and suppressing or modifying others. |
eet AbaR RO raat iels Greil Ne ta ae a a A
| This experiment has discouraging implications for reasoning in everyday
life. It suggests that when people believe a conclusion is true, they are also
very likely to believe arguments that appear to support it, even when these
arguments are unsound. If System 1 is involved, the conclusion comes first
and the arguments follow. |
Untelligence is not only the ability to reason; it is also the ability to find rele-
vant material in memory and to deploy attention when needed. Memory
function is an attribute of System 1. However, everyone has the option of
slowing down to conduct an active search of memory for all possibly rele-
vant facts—just as they could slow down to check the intuitive answer in
the bat-and-ball problem. The extent of deliberate checking and search is a
characteristic of System 2, which varies among individuals. |
ing to pay twice as much as the high scorers.)Frederick’s findings suggest
that the characters of our psychodrama have different “personalities.”
System | is impulsive and intuitive; System 2 is capable of reasoning, and it
is cautious, but at least for some people it is also lazy. We recognize related
differences among individuals: some people are more like their System 2;
others are closer to their System 1. This simple test has emerged as one of
the better predictors of lazy thinking. |

Misco aa ~ waTr ms e e I
f {We call this a priming effect and say that the idea of EAT primes the idea or
~ SOUP, and that WASH primes SOAP. |

Priming effects take many forms. Tf the idea of EAT is currently on your

mind (whether or not you are conscious of it), you will be quicker than
| The idea you should focus on, however, is that disbelief is not an option.
The results are not made up, nor are they statistical flukes. You have no
choice but to accept that the major conclusions of these studies are true.
More important, you must accept that they are true about you. If you had
been exposed to a screen saver of floating dollar bills, you too would likely
have picked up fewer pencils to help a clumsy stranger. You do not believe
that these results apply to you because they correspond to nothing in your
subjective experience. But your subjective experience consists largely of the
story that your System 2 tells itself about what is going on. Priming phe-
nomena arise in System 1, and you have no conscious access to them. |
evocative title Strangers to Ourselves. You have now been introduced to that
stranger in you, which may be in confrol of much of what you do, although
you rarely have a glimpse of it. System 1 provides the impressions that often
turn into your beliefs, and is the source of the impulses that often become
your choices and your actions. It offers a tacit interpretation of what hap-
pens to you and around you, linking the present with the recent past and
with expectations about the near future. It contains the model of the world
that instantly evaluates events as normal or surprising. It is the source of
your rapid and often precise intuitive judgments. And it does most of this
without your conscious awareness of its activities. System 1 is also, as we
will see in the pene chapters, the origin of many of the Syslematic er-

rors in your intuitions. |
indicate the current values of each of these essential variables.}The assess-
ments are carried out automatically by System 1, and one of their functions
is to determine whether extra effort is required from System 2.

One of the dials measures cognitive ease, and its range is between “Easy”
and “Strained.” Easy is a sign that things are going well—no threats, no major
news, no need to redirect attention or mobilize effort. Strained indicates that
a problem exists, which will require increased mobilization of System 2.4
35% when the font was barely legible. iYou read this correctly: performance
was better with the bad font. Cognitive strain, whatever its source, mobi-
lizes oi 2, which is more likely to reject the intuitive answer suggested
by System 1.
} The mere exposure effect does not depend on the conscious experience
of familiarity. In fact, the effect does not depend on consciousness at all: it
occurs even when the repeated words or pictures are shown so quickly that
the observers never become aware of having seen them. They still end up
liking the words or pictures that were presented more frequently. As should
be clear by now, System 1 can respond to impressions of events of which
System 2 is unaware. Indeed, the mere exposure effect is actually stronger
for stimuli that the individual never consciously sees,

es.
common
| These findings add to the growing evidence that good mood, intuition,
creativity, gullibility, and increased reliance on System 1 form a cluster. At
the other pole, sadness, vigilance, suspicion, an analytic approach, and
increased effort also go together. A happy mood loosens the control of
System 2 over performance: when in a good mood, people become more
intuitive and more creative but also less vigilant and more prone to logical
errors. Here again, as in the mere exposure effect, the connection makes
biological sense. A good mood is a signal that things are generally going
well, the environment is safe, and it is all right to let one’s guard down. A
bad mood indicates that things are not going very well, there may be a
threat, and vigilance is required. Cognitive ease is both a cause and a con-
sequence of a pleasant feeling. |
| The main function of System 1 is to maintain and update a model of your
personal world, which represents what is normal in it. The model is con-
structed by associations that link ideas of circumstances, events, actions,
and outcomes that co-occur with some regularity, either at the same time or
within a relatively short interval. As these links are formed and strength-
ened, the pattern of associated ideas comes to represent the structure of
events in your life, and it determines your interpretation of the present as
well as your expectations of the future. |
| UThe most important aspect of both examples is that a definite choice
was made, but you did not know it. Only one interpretation came to
mind, and you were never aware of the ambiguity. System 1 does not keep
track of alternatives that it rejects, or even of the fact that there were alter-
natives. Conscious doubt is not in the repertoire of System 1; it requires
maintaining incompatible interpretations in mind at the same time,
which demands mental effort. Uncertainty and doubt are the domain of
System 2. °
Here we encounter a new aptitude of System 1. An underlying scale of
intensity allows matching across diverse dimensions. If crimes were colors,
murder would be a deeper shade of red than theft; If crimes were expressed
as music, mass murder would be played fortissimo while accumulating un-
Eeropose a simple account of how we generate intuitive opinions on com-
plex matters. Ifa satisfactory answer to a hard question is not found quickly,
System I will find a related question that is easier and will answer it. I call
the operation of answering one question in place of another substitution.}1
The automatic processes of the mental shotgun and intensity matching
often make available one or more answers to easy questions that could be
mapped onto the target question. On some occasions, substitution will occur
and a heuristic answer will be endorsed by System 2. Of course, System 2 has
the opportunity to reject this intuitive answer, or to modify it by incorpo-
rating other information. However, a lazy System 2 often follows the path of
least effort and endorses a heuristic answer without much scrutiny of whether
it is truly appropriate. You will not be stumped, you will not have to work very
hard, and you may not even notice that you did not answer the question you
were asked. Furthermore, you may not realize that the target question was
difficult, because an intuitive answer to it came readily to mind. \

eines
The automatic processes of the mental shotgun and intensity matching
often make available one or more answers to easy questions that could be
mapped onto the target question. On some occasions, substitution will occur
and a heuristic answer will be endorsed by System 2. Of course, System 2 has
the opportunity to reject this intuitive answer, or to modify it by incorpo-
rating other information. However, a lazy System 2 often follows the path of
least effort and endorses a heuristic answer without much scrutiny of whether
itis truly appropriate. You will not be stumped, you will not have to work very
hard, and you may not even notice that you did not answer the question you
were asked. Furthermore, you may not realize that the target question was
difficult, because an intuitive answer to it came readily to mind. \
| The dominance of conclusions over arguments is most pronounced where
emotions are involved. The psychologist Paul Slovic has proposed an affect
heuristic in which people let their likes and dislikes determine their beliefs
about the world. Your political preference determines the arguments that
you find compelling. If you like the current health policy, you believe its
benefits are substantial and its costs more manageable than the costs of
alternatives. If you are a hawk in your attitude toward other nations, you
probably think they are relatively weak and likely to submit to your country’s
will. If you are a dove, you probably think they are strong and will not be
easily coerced. Your emotional attitude to such things as irradiated food,
red meat, nuclear power, tattoos, or motorcycles drives your beliefs about
their benefits and their risks. If you dislike any of these things, you probably
believe that its risks are high and its benefits negligible. |
 

c Are the sequences equally likely? The intuitive answer—“of course not!”—is
false. Because the events are independent and because the outcomes B and
Gare (approximately) equally likely, then any possible sequence of six births
is as likely as any other. Even now that you know this conclusion is true, it
remains counterintuitive, because only the third sequence appears random.
As expected, BGBBGB is judged much more likely than the other two se-
quences. We are pattern seekers, believers in a coherent world, in which
regularities (such as a sequence of six girls) appear not by accident but as a
result of mechanical causality or of someone’ intention. We do not expect
to see regularity produced by a random process, and when we detect what
appears to be a rule, we quickly reject the idea that the process is truly
random. Random processes produce many sequences that convince people
that the process is not random after all. You can see why assuming causality
could have had evolutionary advantages. It is part of the general vigilance
that we have inherited from ancestors. We are automatically on the lookout
for the possibility that the environment has changed. Lions may appear on
the plain at random times, but it would be safer to notice and respond to an
apparent increase in the rate of appearance of prides of lions, even if it is
actually due to the fluctuations of a random process.
Thanks to recent advances in cognitive psychology, we can now see
clearly what Amos and I could only glimpse: the law of small numbers is
part of two larger stories about the workings of the mind.

- The exaggerated faith in small samples is only one example of a more
general illusion—we pay more attention to the content of messages
than to information about their reliability, and as a result end up with
a view of the world around us that is simpler and more coherent than
the data justify. Jumping to conclusions is a safer sport in the world of
our imagination than it is in reality.

¢ Statistics produce many observations that appear to beg for causal ex-
planations but do not lend themselves to such explanations. Many
facts of the world are due to chance, including accidents of sampling.
Causal explanations of chance events are inevitably wrong.
2a

% Vz

[the spin of a wheel of fortune—even one that is not rigged—cannot possibly
“yield useful information about anything, and the participants in our experi-
ment should simply have ignored it. But they did not ignore it. The average
estimates of those who saw 10 and 65 were 25% and 45%, respectively.

The phenomenon we were studying is so common and so important in the
everyday world that you should know its name: it is an anchoring effect. It oc-
curs when people consider a particular value for an unknown quantity before
estimating that quantity. What happens is one of the most reliable and robust
results of experimental psychology: the estimates stay close to the number
that people considered—hence the image of an anchor. If you are asked
| The availability heuristic, like other heuristics of judgment, substitutes
one ne question for another: you wish to estimate the size of a category or the
frequency of an event, but you report an impression of the ease with which
instances come to mind. Substitution of questions inevitably produces sys-
tematic errors. You can discover how the heuristic leads to biases by follow-
ing a simple procedure: list factors other than frequency that make it easy
to come up with instances. Each factor in your list will be a potential source
of bias. Here are some examples: |
| The Alar tale illustrates a basic limitation in the ability of our mind to
deal with small risks: we either ignore them altogether or give them far too
much weight—nothing in between. Every parent who has stayed up waiting
/ The mathematical details are not relevant in this book. [here are two
ideas to keep in mind about Bayesian reasoning and how we tend to mess it
up. The first is that base rates matter, even in the presence of evidence about
the case at hand. This is often not intuitively obvious. The second is that in-
tuitive impressions of the diagnosticity of evidence are often exaggerated.
The combination of WYSIATI and associative coherence tends to make us
believe in the stories we spin for ourselves. The essential keys to disciplined
Bayesian reasoning can be simply summarized:

e Anchor your judgment of the probability of an outcome on a plausible
base rate.
e Question the diagnosticity of your evidence.
{Ihe social norm against stereotyping, including the opposition to pro-
filing, has been highly beneficial in creating a more civilized and more equal
society. It is useful to remember, however, that neglecting valid stereotypes
inevitably results in suboptimal judgments. Resistance to stereotyping is a
laudable moral position, but the simplistic idea that the resistance is cost-
less is wrong. The costs are worth paying to achieve a better society, but
denying that the costs exist, while satisfying to the soul and politically cor-
rect, is not scientifically defensible. Reliance on the affect heuristic is com-
mon in politically charged arguments. The positions we favor have no cost
and those we oppose have no benefits. We should be able to do better
/ this is a profoundly important conclusion. People — are taught sur-
prising statistical facts about human behavior may be ae to the
point of telling their friends about what they have heard, but this does not
mean that their understanding of the world has really changed. ‘The test of
learning psychology is whether your understanding of situations you en-
counter has changed, not whether you have learned a new fact. There is a
deep gap between our thinking about statistics and our thinking about in-
dividual cases. Statistical results with a causal interpretation have a stronger
effect on our thinking than noncausal information. But even compelling
causal statistics will not change long-held beliefs or beliefs rooted in per-
sonal experience. On the other hand, surprising individual cases have a
powerful impact and are a more effective tool for teaching psychology be-
cause the incongruity must be resolved and embedded in a causal story.
That is why this book contains questions that are addressed personally to
the reader. You are more likely to learn something by finding surprises in
your own behavior than by hearing surprising facts about people in

general. |
| The discovery I made on that day was that the flight instructors were
trapped in an unfortunate contingency: because they punished cadets when
performance was poor, they were mostly rewarded by a subsequent im-
provement, even if punishment was actually ineffective. Furthermore, the
instructors were not alone in that predicament. I had stumbled onto a sig-
nificant fact of the human condition: the feedback to which life exposes us
is perverse. Because we tend to be nice to other people when they please us
and nasty when they do not, we are statistically punished for being nice and
rewarded for being nasty. |

Sieamcto™
It took Francis Galton several years to figure out that correlation and
Befession are not two concepts—they are different perspectives on the
same concept. The general rule is straightforward but has surprising conse-
quences: whenever the correlation between two scores is imperfect, there
will be regression to the mean, To illustrate Galton’s insight, take a proposi-
member thinking it) could not conclusively show it at the time Many intel-
ligent and well-informed people were keenly interested in the future of the
economy and did not believe a catastrophe was imminent; I infer from this
fact that the crisis was not knowable. What is perverse about the use of
know in this context is not that some individuals get credit for prescience
that they do not deserve. It is that the language implies that the world is
more knowable than it is. It helps perpetuate a pernicious illusion.

The core of the illusion is that we believe we understand the past, which
implies that the future also should be knowable, but in fact we understand
the past less than we believe we do.' Know i is not the only word that fosters
‘The mind that makes up narratives about the past is a sense-making organ.
pee an unpredicted event occurs, we immediately adjust our view of the
world to accommodate the surprise. Imagine yourself before a football
game between two teams that have the same record of wins and losses. Now
the game is over, and one team trashed the other. In your revised model of
the world, the winning team is much stronger than the loser, and your view
of the past as well as of the future has been altered by that new perception.
Learning from surprises is a reasonable thing to do, but it can have some
dangerous consequences.

A general limitation of the human mind is its imperfect ability to recon-
struct past states of knowledge, or beliefs that have changed. Once you adopt
a new view of the world (or of any part of it), you immediately lose much of
your ability to recall what you used to believe before your mind changed.

Many psychologists have studied what happens when people change
their minds. Choosing a topic on which minds are not completely made
up—say, the death penalty—the experimenter carefully measures peoples —
attitudes. Next, the participants see or hear a Persuasive pro or con mes-
sage. Then the experimenter measures people's attitudes again; they usually
are closer to the persuasive message they were exposed to. Finally, the par-
ticipants report the opinion they held beforehand. This task turns out to be
surprisingly difficult. Asked to reconstruct their former beliefs, people re-
trieve their current ones instead—an instance of substitution—and many
cannot believe that they ever felt differently.’
Clinton! The tendency to revise the history of one’s beliefs in light of what
actually happened produces a robust cognitive illusion. —

Hindsight bias has pernicious effects on the evaluations of decision
makers. It leads observers to assess the quality of a decision not by whether
the process was sound but by whether its outcome was good or bad. Con-
sider a low-risk surgical intervention in which an unpredictable accident
occurred that caused the patient’s death. The jury will be prone to believe,
after the fact, that the operation was actually risky and that the doctor who
ordered it should have known better. This outcome bias makes it almost
_impossible to evaluate a decision properly—in terms of the beliefs that were
reasonable when the decision was made.

Hindsight is especially unkind to decision makers who act as agents for
others—physicians, financial advisers, third-base coaches, CEOs, social
workers, diplomats, politicians. We are prone to blame decision makers for
good decisions that worked out badly and to give them too little credit
for successful moves that appear obvious only after the fact. There is a clear
outcome bias.| When the outcomes are bad, the clients often blame their
| Subjective confidence in wr judgment is not a reasoned evaluation of the
probability that this judgment is correct. Confidence is a feeling, which re-
flects the coherence of the information and the cognitive ease of processing
it. It is wise to take admissions of uncertainty seriously, but declarations of
high confidence mainly tell you that an individual has constructed a co-
herent story in his mind, not necessarily that the story is true. ;

‘TE, #
Seite
The most potent psychological cause of the illusion is certainly that the
people who pick stocks are exercising high-level skills. They consult eco-
nomic data and forecasts, they examine income statements and balance
sheets, they evaluate the quality of top management, and they assess the
competition. All this is serious work that requires extensive training, and
the people who do it have the immediate (and valid) experience of using
these skills. Unfortunately, skill in evaluating the business prospects of a
firm is not sufficient for successful stock trading, where the key question is
whether the information about the firm is already incorporated in the price
of its stock. Traders apparently lack the skill to answer this crucial question,
but they appear to be ignorant of their ignorance. As I had discovered from
watching cadets on the obstacle field, subjective confidence of traders is a
feeling, not a judgment. Our understanding of cognitive ease and associa-
tive coherence locates subjective confidence firmly in System 1.
The idea that the future is unpredictable is undermined every day by the
ease with which the past is explained. As Nassim Taleb pointed out in The
Black Swan, our tendency to construct and believe coherent narratives of
the past makes it difficult for us to accept the limits of our forecasting ability.
Everything makes sense in hindsight, a fact that financial pundits exploit
every evening as they offer convincing accounts of the day’s events. And we
cannot suppress the powerful intuition that what makes sense in hindsight
today was predictable yesterday. The illusion that we understand the past
fosters overconfidence in our ability to predict the future. ’
  
 
 

yr : results were devastating. Ihe experts performed worse than they 7
would have if they had simply assigned equal probabilities to each of the _
three potential outcomes. In other words, people who spend their time, and
earn their living, studying a particular topic produce poorer predictions
than dart-throwing monkeys who would have distributed their choices
evenly over the options. Even in the region they knew best, experts were not
significantly better than nonspecialists.

Those who know more forecast very slightly better than those who know
less. But those with the most knowledge are often less reliable. The reason is
that the person who acquires more knowledge develops an enhanced illu-
sion of her skill and becomes unrealistically overconfident. “We reach the
point of diminishing marginal predictive returns for knowledge discon-
certingly quickly,” Tetlock writes. “In this age of academic hyperspe-
cialization, there is no reason for supposing that contributors to top
journals—distinguished political scientists, area study specialists, econo-
mists, and so on—are any better than journalists or attentive readers of The
New York Times in ‘reading’ emerging situations.” The more famous the
forecaster, Tetlock discovered, the more flamboyant the forecasts. “Experts
in demand.” he writes, “were more overconfident than their colleagues who

eked out existences far from the limelight’ j
| why are experts inferior to algorithms? One ae ny and ea
pected, is that experts try to be clever, think outside t é ox, con
complex combinations of features in making thet prechenious. a a
may work in the odd case, but more often than not it reduces validity. Simple
combinations of features are better. Several studies have shown that human
decision makers are inferior to a prediction formula even when they are
given the score suggested by the formula! They feel that they can overrule
the formula because they have additional information about the case, but
they are wrong more often than not. According to Meehl, there are few
circumstances under which it is a good idea to substitute judgment for a
formula. In a famous thought experiment, he described a formula that pre-
dicts whether a particular person will go to the movies tonight and noted
that it is proper to disregard the formula if information is received that the
individual broke a leg today. The name “broken-leg rule” has stuck. The
point, of course, is that broken legs are very rare—as well as decisive.!

Ace et ee ES. ie r
/ The widespread inconsistency is probably due to the extreme context
dependency of System 1. We know from studies of priming that unnoticed
stimuli in our environment have a substantial influence on our thoughts
and actions. These influences fluctuate from moment to moment. The brief
pleasure of a cool breeze on a hot day may make you slightly more positive
and optimistic about whatever you are evaluating at the time. The prospects
of a convict being granted parole may change significantly during the time
that elapses between successive food breaks in the parole judges’ schedule.
Because you have little direct knowledge of what goes on in your mind, you
will never know that you might have made a different judgment or reached
a different decision under very slightly different circumstances. Formulas
do not suffer from such problems. Given the same input, they always return
the same answer. When predictability is poor—which it is in most of the
studies reviewed by Meehl and his followers—inconsistency is destructive
of any predictive validity.’ |
a FS SEBO re ge. s&vO

ee, Seymour, the rest of us did not have access to the outside view
and could not have produced a reasonable baseline prediction. It is note-
worthy, however, that we did not feel we needed information about other
teams to make our guesses. My request for the outside view surprised all of
us, including me! This is a common pattern: people who have information
about an individual case rarely feel the need to know the statistics of the
class to which the case belongs.

When we were eventually exposed to the outside view, we collectively
ignored it. We can recognize what happened to us; it is similar to the exper-
iment that suggested the futility of teaching psychology. When they made
predictions about individual cases about which they had a little informa-
tion (a brief and bland interview), Nisbett and Borgida’s students completely
neglected the global results they had just learned. “Pallid” statistical infor-
mation is routinely discarded when it is incompatible with one’s personal
impressions of a case. In the competition with the inside view, the outside

° > f
view doesn't stand a chance. |

Tr
This may be considered the single most important piece of advice re-
‘garding how to increase accuracy in forecasting through improved meth-
ods. Using such distributional information from other ventures similar to

that being forecasted is called taking an “outside view” and is the cure to the
planning fallacy./
expected} This shows that CFOs were grossly overconfident about their
ability to forecast the market. Overconfidence is another manifestation of
WYSIATI: when we estimate a quantity, we rely on information that comes
to mind and construct a coherent story in which the estimate makes sense,
Allowing for the information that does not come to mind—perhaps be-
cause one never knew it—is impossible. )

pila
people do! The rejection of this gamble is an act of System 2, but the critical
inputs are emotional responses that are generated by System 1. For most
people, the fear of losing $100 is more intense than the hope of gaining
$150. We concluded from many such observations tha	t “losses loom larger
than gains” and that people are loss averse. |
: As you carried out this exercise, you probably found that your loss aver-
“Sion coefficient tends to increase when the stakes rise, but not dramati-
cally. All bets are off, of course, if the possible loss is potentially ruinous, or
if your lifestyle is threatened. The loss aversion coefficient is very large in
such cases and may even be infinite—there are risks that you will not ac-
cept, regardless of how many millions you might stand to win if you are

lucky. |
—_

i ° ° *

¢ In mixed gambles, where both a gain and a loss are possible, loss aver-
sion causes extremely risk-averse choices.

e In bad choices, where a sure loss is compared to a larger loss that is

merely probable, diminishing sensitivity causes risk seeking.

There is no contradiction. In the mixed case, the possible loss looms twice
as large as the possible gain, as you can see by comparing the slopes of
the value function for losses and gains. In the bad case, the bending of —
the value curve (diminishing sensitivity) causes risk seeking. The pain
of losing $900 is more than 90% of the pain of losing $1,000. These two
insights are the essence of prospect theory. \

a
 

Ler oe semen =" en ror Aha

/ Richard Thaler found many examples of what he called the endowment
effect, especially for goods that are not regularly traded. You can easily
imagine yourself in a similar situation. Suppose you hold a ticket to a sold-
out concert by a popular band, which you bought at the regular price of
$200. You are an avid fan and would have been willing to pay up to $500 for
the ticket. Now you have your ticket and you learn on the Internet that
richer or more desperate fans are offering $3,000. Would you sell? If you
resemble most of the audience at sold-out events you do not sell. Your low-
est selling price is above $3,000 and your maximum buying price is $500.
This is an example of an endowment effect, and a believer in standard eco-
nomic theory would be puzzled by it. Thaler was looking for an account

i

that could explain puzzles of this kind. |
pen ut Roh Neat mere eee ae ye a a ae

| Chance intervened when Thalevtnet one of our former students at a
conference and obtained an early draft of prospect theory. He reports that
he read the manuscript with considerable excitement, because he quickly
realized that the loss-averse value function of prospect theory could explain
the endowment effect and some other puzzles in his collection. The solu-
tion was to abandon the standard idea that Professor R had a unique utility
for the state of having a particular bottle. Prospect theory suggested that the
willingness to buy or sell the bottle depends on the reference point—
whether or not the professor owns the bottle now. If he owns it, he consid-
ers the pain of giving up the bottle. If he does not own it, he considers the
pleasure of getting the bottle. The values were unequal because of loss aver-
sion: giving up a bottle of nice wine is more painful than getting an equally
good bottle is pleasurable. Remember the graph of losses and gains in the
previous chapter. The slope of the function is steeper in the negative do-
main; the response to a loss is stronger than the response to a correspond-
ing gain. This was the explanation of the endowment effect that Thaler had
been searching for. [And the first application of prospect theory to an eco-

Sip ci RO
la large majority (73%) considered this action Acceptable. It appears that

l she employer does not have a moral obligation to pay $9 an hour. The enti-
tlement is personal: the current worker has a right to retain his wage even if
market conditions would allow the employer to impose a wage cut. The re-
placement worker has no entitlement to the previous worker’s reference
wage, and the employer is therefore allowed to reduce pay without the risk
of being branded unfair.

The firm has its own entitlement, which is to retain its current profit. If
it faces a threat of a loss, it is allowed to transfer the loss to others. A sub-
stantial majority of respondents believed that it is not unfair for a firm to
reduce its workers’ wages when its profitability is falling. We described the
rules as defining dual entitlements to the firm and to individuals with whom
it interacts. When threatened, it is not unfair for the firm to be selfish. It is
not even expected to take on part of the losses; it can pass them on.|
EB The conclusion is straightforward: the decision weights that people
assign to outcomes are not identical to the probabilities of these outcomes,
contrary to the expectation principle. Improbable outcomes are over-
weighted—this is the possibility effect. Outcomes that are almost certain
are underweighted relative to actual certainty. The expectation principle, by
which values are weighted by their probability, is poor psychology.

The plot thickens, however, because there is a powerful argument that a
decision maker who wishes to be rational must conform to the expectation
principle. This was the main point of the axiomatic version of utility theory
that von Neumann and Morgenstern introduced in 1944) They proved that
- nore the very rare events, you will certainly overweight them. Most of us
~ spend very little time worrying about nuclear meltdowns or fantasizing
about large inheritances from unknown relatives. However, when an un-
likely event becomes the focus of attention, we will assign it much more
weight than its probability deserves. Furthermore, people are almost
completely insensitive to variations of risk among small probabilities. A
cancer risk of 0.001% is not easily distinguished from a risk of 0.00001%,
although the former would translate to 3,000 cancers for the population of
the United States, and the latter to 30.)
/ First, there is diminishing sensitivity. The sure loss is very aversive be-
cause the reaction to a loss of $900 is more than 90% as intense as the
reaction to a loss of $1,000. The second factor may be even more powerful:
the decision weight that corresponds to a probability of 90% is only about
71, much lower than the probability. The result is that when you consider a
choice between a sure loss and a gamble with a high probability of a larger
loss, diminishing sensitivity makes the sure loss more aversive, and the cer-
tainty effect reduces the aversiveness of the gamble. The same two factors
enhance the attractiveness of the sure thing and reduce the attractiveness of
the gamble when the outcomes are positive.

The shape of the value function and the decision weights both con-
tribute to the pattern observed in the top row of table 13. In the bottom row,
however, the two factors operate in opposite directions: diminishing sensi-
tivity continues to favor risk aversion for gains and risk seeking for losses,
but the overweighting of low probabilities overcomes this effect and pro-
duces the observed pattern of gambling for gains and caution for losses.

Many unfortunate human situations unfold in the top right cell. This is
where people who face very bad options take desperate gambles, accepting
a high probability of making things worse in exchange for a small hope of
avoiding a large loss. Risk taking of this kind often turns manageable fail-
ures into disasters. The thought of accepting the large sure loss is too pain-
ful, and the hope of complete relief too enticing, to make the sensible
decision that it is time to cut one’s losses. This is where businesses that are
losing ground to a superior technology waste their remaining assets in fu-
tile attempts to catch up. Because defeat is so difficult to accept, the losing
side in wars often fights long past the point at which the victory of the other
side is certain, and only a matter of time. |
|_The example also shows that it is costly to be risk averse for gains and
risk seeking for losses. These attitudes make you willing to pay a premium
to obtain a sure gain rather than face a gamble, and also willing to pay a
premium (in expected value) to avoid a sure loss. Both payments come out
combination of loss aversion and narrow framing is a costly curse.
Individual investors can avoid that curse, achieving the emotional benefits
of broad framing while also saving time and agony, by reducing the
frequency with which they check how well their investments are doing.
Closely following daily fluctuations is a losing proposition, because the pain
of the frequent small losses exceeds the pleasure of the equally frequent
small gains. Once a quarter is enough, and may be more than enough for
individual investors. In addition to improving the emotional quality of life,
the deliberate avoidance of exposure to short-term outcomes improves the
quality of both decisions and outcomes. The typical short-term reaction to
bad news is increased loss aversion. Investors who get aggregated feedback
receive such news much less often and are likely to be less risk averse and to
end up richer. You are also less prone to useless churning of your portfolio
if you don't know how every stock in it is doing every day (or every week or
even every month). A commitment not to change one’s position for several

periods (the equivalent of “locking in” an investment) improves financial
erformance. |
e gb
es rational decision maker is interested only in the future consequences
of current investments. Justifying earlier mistakes is not among the Econ’s
concerns. The decision to invest additional resources in a losing account,
when better investments are available, is known as the sunk-cost fallacy, a
costly mistake that is observed in decisions large and small. Driving into
the blizzard because one paid for tickets is a sunk-cost error. |
The results are clear-cut: 8% of respondents say Paul, 92% say George.
This is curious, because the situations of the two investors are objec-
tively identical. They both now own stock A and both would have been
better off by the same amount if they owned stock B. The only difference js
that George got to where he is by acting, whereas Paul got to the same place
by failing to act. This short example illustrates a broad story: people expect
to have stronger emotional reactions (including regret) to an outcome that
is produced by action than to the same outcome when it is produced by in-
action. This has been verified in the context of gambling: people expect to
be happier if they gamble and win than if they refrain from gambling and
get the same amount. The asymmetry is at least as strong for losses, and it
applies to blame as well as to regret. The key is not the difference between
commission and omission but the distinction between default options and
actions that deviate from the default. When you deviate from the default,
you can easily imagine the norm—and if the default is associated with bad
consequences, the discrepancy between the two can be the source of pain-
ful emotions. The default option when you own a stock is not to sell it, but
the default option when you meet your colleague in the morning is to greet
him. Selling a stock and failing to greet your coworker are both departures
from the default option and natural candidates for regret or blame. }
There is another sense of meaning,

| in which “Italy won” and “France
lost” do not have the same Meaning at

all. In this sense, the meaning of a
sentence is what happens in your associative machinery while you under-

stand it. The two sentences evoke markedly different associations. “Italy
won evokes thoughts of the Italian team and what it did to win. “France
lost” evokes thoughts of the French team and what it did that caused it to
lose, including the memorable head butt of an Italian player by the French
star Zidane. In terms of the associations they bring to mind—how System 1
reacts to them—the two sentences really “mean” different things. The fact
that logically equivalent statements evoke different reactions makes it im-
possible for Humans to be as reliably rational as BeOn aay

.
©
| The KEEP-LOSE study and the survival—mortality experiment differed
in one important respect. ‘The participants in the brain-imaging study had
many trials in which they encountered the different frames. They had an
opportunity to recognize the distracting effects of the frames and to sim-
plify their task by adopting a common frame, perhaps by translating the
LOSE amount into its KEEP equivalent. It would take an intelligent person
(and an alert System 2) to learn to do this, and the few participants who
managed the feat were probably among the “rational” agents that the ex-
perimenters identified. In contrast, the physicians who read the statistics
about the two therapies in the survival frame had no reason to suspect that
they would have made a different choice if they had heard the same statis-
tics framed in terms of mortality. Reframing is effortful and System 2 is
normally lazy. Unless there is an obvious reason to do otherwise, most of us
passively accept decision problems as they are framed and therefore rarely
have an opportunity to discover the extent to which our preferences are

frame-bound rather than reality-bound. ;

nCueR
& Here again, you will probably find yourself dumbfounded. You have
moral intuitions about differences between the rich and the poor, but these
intuitions depend on an arbitrary reference point, and they are not about
the real problem. This problem—the question about actual states of the
world—is how much tax individual families should pay, how to fill the cells
in the matrix of the tax code. You have no compelling moral intuitions to
guide you in solving that problem. Your moral feelings are attached to
frames, to descriptions of reality rather than to reality itself. The message
about the nature of framing is stark: framing should not be viewed as an
intervention that masks or distorts an underlying preference. At least in this
instance—and also in the problems of the Asian disease and of surgery
versus radiation for lung cancer—there is no underlying preference that is
masked or distorted by the frame. Our preferences are about framed prob-

lems, and our moral intuitions are about descriptions, not about substance. /

oe RETEST
| Confusing experience with the memory of it is a compelling cognitive
illusion—and it is the substitution that makes us believe a past experience
can be ruined. The experiencing self does not have a voice. The remem- —
bering self is sometimes wrong, but it is the one that keeps score and gov-
erns what we learn from living, and it is the one that makes decisions. What
we learn from the past is to maximize the qualities of our future memories,
not necessarily of our future experience. This is the tyranny of the remem-
bering self.)
: | For another thought experiment, imagine you face a painful operation

during which you will remain conscious. You are told you will scream in

pain and beg the surgeon to stop. However, you are promised an amnesia-

inducing drug that will completely wipe out any memory of the episode.
How do you feel about such a prospect? Here again, my informal observa-
tion is that most people are remarkably indifferent to the pains of their
experiencing self. Some say they don't care at all. Others share my feeling,
which is that I feel pity for my suffering self but not more than I would feel
for a stranger in pain. Odd as it may seem, I am my remembering self, and
the experiencing self, who does my living, is like a stranger to me. |
e. is a clear contrast between the effects of income on experienced
well-being and on life satisfaction. Higher income brings with it higher sat-
isfaction, well beyond the point at which it ceases to have any positive effect
on experience. The general conclusion is as clear for well-being as it was for
colonoscopies: people's evaluations of their lives and their actual experience
may be related, but they are also different. Life satisfaction is not a flawed
measure of their experienced well-being, as I thought some years ago. It is
something else entirely. |

ar OSB eh)
the only thing that comes to mind when you are asked to evaluate your life,
/You are likely to be reminded of significant events in your recent past or
near future; of recurrent concerns, such as the health of a spouse or the bad
company that your teenager keeps; of important achievements and painful
failures. A few ideas that are relevant to the question will occur to you;
many others will not. Even when it is not influenced by completely irrele-
vant accidents such as the coin on the machine, the score that you quickly
assign to your life is determined by a small sample of highly available ideas,
not by a careful weighting of the domains of your life./
cially as an essential goal: .57 point on a 5-point scale) The corresponding
difference for those who had indicated that money was not important was
only .12. The people who wanted money and got it were significantly more
satisfied than average; those who wanted money and didn't get it were sig-
nificantly more dissatisfied. The same principle applies to other goals—one
recipe for a dissatisfied adulthood is setting goals that are especially difficult
to attain. Measured by life satisfaction 20 years later, the least promising
goal that a young person could have was “becoming accomplished in a per-
forming art.’ Teenagers’ goals influence what happens to them, where they
end up, and how satisfied they are. _

_In part because of these findings I have changed my mind about the def-
inition of well-being. The goals that people set for themselves are so impor-
tant to what they do and how they feel about it that an exclusive focus on
experienced well-being is not tenable. We cannot hold a concept of well-
being that ignores what people want. On the other hand, it is also true that
a concept of well-being that ignores how people feel as they live and focuses
only on how they feel when they think about their life is also untenable. We
must accept the complexities of a hybrid view, in which the well-being of
both selves is Lary
We can infer from the speed with which people respond to questions about
their life, and from the effects of current mood on their responses, that they
do not engage in a careful examination when they evaluate their life. They
must be using heuristics, which are examples of both substitution and
WYSIATI. Although their view of their life was influenced by a question
about dating or by a coin on the copying machine, the participants in these
studies did not forget that there is more to life than dating or feeling lucky.
The concept of happiness is not suddenly changed by finding a dime, but Sys-
tem 1 readily substitutes a small part of it for the whole of it. Any aspect of life
to which attention is directed will loom large in a global evaluation. This is the
essence of the focusing illusion, which can be described in a single sentence:

Nothing in life is as important as you think it is when you are thinking

about it. |
\._Compare two commitments that will change some aspects of your life:
buying a comfortable new car and joining a group that meets weekly, per-
haps a poker or book club. Both experiences will be novel and exciting at
the start. The crucial difference is that you will eventually pay little attention
to the car as you drive it, but you will always attend to the social interac-
tion to which you committed yourself. By WYSIATI, you are likely to exag-
gerate the long-term benefits of the car, but you are not likely to make the
same mistake for a social gathering or for inherently attention-demanding
activities such as playing tennis or learning to play the cello. The focusing
illusion creates a bias in favor of goods and experiences that are initially
exciting, even if they will eventually lose their appeal. Time is neglected,
causing experiences that will retain their attention value in the long term to
be appreciated less than they deserve to be. |
| The role of time has been a refrain in this part of the book. It is logical to
me: Mbibscribe the life of the experiencing self as a series of moments, each with a
value. The value of an episode—I have called it a hedonimeter total—is
simply the sum of the values of its moments. But this is not how the mind
represents episodes. The remembering self, as I have described it, also tells
stories and makes choices, and neither the stories nor the choices properly
represent time. In storytelling mode, an episode is represented by a few crit-
ical moments, especially the beginning, the peak, and the end. Duration is
neglected. We saw this focus on singular moments both in the cold-hand
situation and in Violetta’s story.

We saw a different form of duration neglect in prospect theory, in which
a state is represented by the transition to it. Winning a lottery yields a new
state of wealth that will endure for some time, but decision utility corre-
sponds to the anticipated intensity of the reaction to the news that one has
won. The withdrawal of attention and other adaptations to the new state are
neglected, as only that thin slice of time is considered. The same focus on
the transition to the new state and the same neglect of time and adaptation
are found in forecasts of the reaction to chronic diseases, and of course in
the focusing illusion. The mistake that people make in the focusing illusion
involves attention to selected moments and neglect of what happens at
other times. The mind is good with stories, but it does not appear to be well
designed for the processing of time.

During the last ten years we have learned many new facts about happi-
ness. But we have also learned that the word happiness does not have a
simple meaning and should not be used as if it does. Sometimes scientific
progress leaves us more puzzled than we were before. |
What can be done about biases? How can we improve judgments and
decisions, both our own and those of the institutions that we serve and that
serve us? The short answer is that little can be achieved without a consider-
able investment of effort. As I know from experience, System 1 is not readily
educable. Except for some effects that I attribute mostly to age, my intuitive
thinking is just as prone to overconfidence, extreme predictions, and the
planning fallacy as it was before I made a study of these issues. I have im-
proved only in my ability to recognize situations in which errors are likely:
“This number will be an anchor . . . ,” “The decision could change if the
problem is reframed . . ” And I have made much more progress in recog-
nizing the errors of others than my own.

The way to block errors that originate in System 1 is simple in principle:
recognize the signs that you are in a cognitive minefield, slow down, and
ask for reinforcement from System 2. This is how you will proceed when

you next encounter the Miiller-Lyer illusion. When you see lines with fins
pointing in different directions, you will recognize the situation as one in
which you should not trust your impressions of length. Unfortunately, this
sensible procedure is least likely to be applied when it is needed most. We
would all like to have a warning bell that rings loudly whenever we are
about to make a serious error, but no such bell is available, and cognitive
illusions are generally more difficult to recognize than perceptual illusions. |
